{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e778cf13",
   "metadata": {},
   "source": [
    "# Fuel-Efficient Route Model Training\n",
    "\n",
    "This notebook trains **two neural network models**:\n",
    "\n",
    "1. **Fuel Consumption Model**\n",
    "2. **CO₂ Emissions Model**\n",
    "\n",
    "using vehicle and traffic data to estimate the most fuel-efficient route.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "1. Ensure the required CSV files are in the correct locations:\n",
    "   - `../data/vehicle data/vehicles.csv`\n",
    "   - `../data/traffic data/Traffic_Volumes.csv`\n",
    "   - `../data/traffic data/Bottlenecks.csv`\n",
    "2. Install the necessary dependencies (e.g., `pip install pandas numpy scikit-learn tensorflow`).\n",
    "3. Run the cells sequentially.\n",
    "4. After training, the models will be saved as `.h5` files in the `../models/` directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396be23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "print(\"Libraries imported successfully.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fccc1d57",
   "metadata": {},
   "source": [
    "## 2. Load and Inspect Datasets\n",
    "\n",
    "We load the CSV files containing:\n",
    "- Vehicle data (fuel efficiency & CO₂ emissions)\n",
    "- Traffic volumes (historical traffic patterns)\n",
    "- Bottlenecks (areas of high congestion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443819c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load and Inspect Datasets\n",
    "vehicle_data = pd.read_csv('../data/vehicle data/vehicles.csv')\n",
    "traffic_volumes = pd.read_csv('../data/traffic data/Traffic_Volumes.csv')\n",
    "bottlenecks = pd.read_csv('../data/traffic data/Bottlenecks.csv')\n",
    "\n",
    "print(\"Vehicle Data Sample:\")\n",
    "print(vehicle_data.head())\n",
    "\n",
    "print(\"\\nTraffic Volumes Sample:\")\n",
    "print(traffic_volumes.head())\n",
    "\n",
    "print(\"\\nBottlenecks Sample:\")\n",
    "print(bottlenecks.head())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd0aaf44",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning and Preprocessing\n",
    "\n",
    "Steps:\n",
    "- Drop rows with missing values.\n",
    "- Rename columns in the vehicle data for clarity.\n",
    "- Compute a combined fuel efficiency (weighted average: 55% city, 45% highway).\n",
    "- Normalize the traffic congestion severity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56839a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Data Cleaning and Preprocessing\n",
    "\n",
    "# Drop rows with missing values\n",
    "vehicle_data.dropna(inplace=True)\n",
    "traffic_volumes.dropna(inplace=True)\n",
    "bottlenecks.dropna(inplace=True)\n",
    "\n",
    "# Rename columns in vehicle_data for clarity\n",
    "vehicle_data.rename(\n",
    "    columns={\n",
    "        'Fuel_Consumption_City': 'city_fuel_efficiency',\n",
    "        'Fuel_Consumption_Hwy': 'highway_fuel_efficiency',\n",
    "        'CO2_Emissions': 'co2_emissions'\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# Compute combined fuel efficiency (weighted: 55% city, 45% highway)\n",
    "vehicle_data['combined_fuel_efficiency'] = (\n",
    "    vehicle_data['city_fuel_efficiency'] * 0.55 +\n",
    "    vehicle_data['highway_fuel_efficiency'] * 0.45\n",
    ")\n",
    "\n",
    "# Normalize traffic congestion severity (scale 0 to 1)\n",
    "bottlenecks['normalized_traffic_severity'] = (\n",
    "    bottlenecks['traffic_severity'] / bottlenecks['traffic_severity'].max()\n",
    ")\n",
    "\n",
    "print(\"Data cleaning and preprocessing complete.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74847997",
   "metadata": {},
   "source": [
    "## 4. Merge Datasets\n",
    "\n",
    "Steps:\n",
    "1. Merge traffic volumes with bottlenecks on `location`.\n",
    "2. Merge the resulting traffic data with vehicle data on `Fuel_Type`.\n",
    "3. Compute `fuel_consumption` as: distance / combined_fuel_efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e4b170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Merge Datasets\n",
    "\n",
    "# Merge traffic volumes with bottlenecks (on 'location')\n",
    "traffic_data = pd.merge(\n",
    "    traffic_volumes,\n",
    "    bottlenecks[['location', 'normalized_traffic_severity']],\n",
    "    on='location',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Merge the traffic data with vehicle_data on 'Fuel_Type'\n",
    "merged_data = traffic_data.merge(\n",
    "    vehicle_data,\n",
    "    on='Fuel_Type',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Compute estimated fuel consumption: Fuel Consumption = distance / combined_fuel_efficiency\n",
    "merged_data['fuel_consumption'] = merged_data['distance'] / merged_data['combined_fuel_efficiency']\n",
    "\n",
    "print(\"Merged Data Sample:\")\n",
    "print(merged_data.head())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f20e4e5",
   "metadata": {},
   "source": [
    "## 5. Select Features and Targets\n",
    "\n",
    "- **Features (X):** `distance`, `normalized_traffic_severity`, `combined_fuel_efficiency`\n",
    "- **Targets:**\n",
    "  - `y_fuel` for fuel consumption prediction\n",
    "  - `y_co2` for CO₂ emissions prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c4c576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Select Features and Targets\n",
    "X = merged_data[['distance', 'normalized_traffic_severity', 'combined_fuel_efficiency']]\n",
    "y_fuel = merged_data['fuel_consumption']\n",
    "y_co2 = merged_data['co2_emissions']\n",
    "\n",
    "print(\"Features (X) shape:\", X.shape)\n",
    "print(\"Fuel Consumption (y_fuel) shape:\", y_fuel.shape)\n",
    "print(\"CO₂ Emissions (y_co2) shape:\", y_co2.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3776f7be",
   "metadata": {},
   "source": [
    "## 6. Train-Test Split\n",
    "\n",
    "We split the data into training (80%) and testing (20%) sets for both targets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e79f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Train-Test Split\n",
    "X_train, X_test, y_fuel_train, y_fuel_test = train_test_split(\n",
    "    X, y_fuel,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# For CO₂ Emissions, using the same split indices\n",
    "_, _, y_co2_train, y_co2_test = train_test_split(\n",
    "    X, y_co2,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Fuel data:\", X_train.shape, X_test.shape, y_fuel_train.shape, y_fuel_test.shape)\n",
    "print(\"CO₂ data:\", y_co2_train.shape, y_co2_test.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d227210",
   "metadata": {},
   "source": [
    "## 7. Scale the Features\n",
    "\n",
    "We apply **StandardScaler** separately for each model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ce585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Scale the Features\n",
    "\n",
    "# Scale for Fuel Consumption Model\n",
    "scaler_fuel = StandardScaler()\n",
    "X_train_fuel = scaler_fuel.fit_transform(X_train)\n",
    "X_test_fuel = scaler_fuel.transform(X_test)\n",
    "\n",
    "# Scale for CO₂ Emissions Model\n",
    "scaler_co2 = StandardScaler()\n",
    "X_train_co2 = scaler_co2.fit_transform(X_train)\n",
    "X_test_co2 = scaler_co2.transform(X_test)\n",
    "\n",
    "print(\"Feature scaling complete.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4487b428",
   "metadata": {},
   "source": [
    "## 8. Define the Keras Model\n",
    "\n",
    "We build a simple feedforward neural network with two hidden layers and dropout.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9409cdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Define a Reusable Keras Model\n",
    "def build_model(input_dim):\n",
    "    \"\"\"\n",
    "    Creates a simple feedforward neural network for regression tasks.\n",
    "    \n",
    "    Args:\n",
    "        input_dim (int): Number of input features.\n",
    "    \n",
    "    Returns:\n",
    "        model (Sequential): Compiled Keras model.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='mse',\n",
    "        metrics=['mse']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "print(\"Model builder function defined.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d855352",
   "metadata": {},
   "source": [
    "## 9. Train the Fuel Consumption Model\n",
    "\n",
    "We train the model using `X_train_fuel` and `y_fuel_train` with a validation split of 20%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f118ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Train the Fuel Consumption Model\n",
    "print(\"Training Fuel Consumption Model...\")\n",
    "model_fuel = build_model(input_dim=X_train_fuel.shape[1])\n",
    "history_fuel = model_fuel.fit(\n",
    "    X_train_fuel, y_fuel_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3765fdc5",
   "metadata": {},
   "source": [
    "## 10. Train the CO₂ Emissions Model\n",
    "\n",
    "We train a second model using `X_train_co2` and `y_co2_train`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e146e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Train the CO₂ Emissions Model\n",
    "print(\"\\nTraining CO₂ Emissions Model...\")\n",
    "model_co2 = build_model(input_dim=X_train_co2.shape[1])\n",
    "history_co2 = model_co2.fit(\n",
    "    X_train_co2, y_co2_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a8011e8",
   "metadata": {},
   "source": [
    "## 11. Evaluate Model Performance\n",
    "\n",
    "We evaluate both models on the test set and print the Mean Squared Error (MSE).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9f2327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Evaluate Model Performance\n",
    "fuel_loss, fuel_mse = model_fuel.evaluate(X_test_fuel, y_fuel_test, verbose=0)\n",
    "co2_loss, co2_mse = model_co2.evaluate(X_test_co2, y_co2_test, verbose=0)\n",
    "\n",
    "print(f\"\\nFuel Consumption Model MSE: {fuel_mse:.4f}\")\n",
    "print(f\"CO₂ Emissions Model MSE: {co2_mse:.4f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b496db6",
   "metadata": {},
   "source": [
    "## 12. Save Trained Models\n",
    "\n",
    "The models are saved as `.h5` files in the `../models/` directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6d0c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Save Trained Models\n",
    "model_fuel.save('../models/fuel_consumption_model.h5')\n",
    "model_co2.save('../models/co2_emissions_model.h5')\n",
    "\n",
    "print(\"\\n✅ Models saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5 (main, Sep 11 2023, 08:31:25) [Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "d9a4aab999b09d34f67d26c6144e1baa6f2c0c050bd4fb9a952b08e795c982eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
